{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb4f94c8",
   "metadata": {},
   "source": [
    "# Funciones analisis Fintech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c88c775",
   "metadata": {},
   "source": [
    "## Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b991573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as est√°ndar\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Manipulaci√≥n de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuraci√≥n de warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# An√°lisis de nulos\n",
    "import missingno as msno\n",
    "\n",
    "# Visualizaci√≥n de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Textos\n",
    "import unicodedata\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "\n",
    "# Estadistica\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b7c29",
   "metadata": {},
   "source": [
    "## Funciones de lectura de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edad5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion carga de archivos.\n",
    "def carga_archivos(path):\n",
    "    # Lista de los archivos en el directorio.\n",
    "    lista = os.listdir(path)\n",
    "    print(f\"üìÇ Total archivos encontrados: {len(lista)}\")\n",
    "    print(lista)\n",
    "    print('*' * 80)\n",
    "\n",
    "    # Filtrado archivos .csv y .xlsx (CORREGIDO: usar 'or' en lugar de '|')\n",
    "    files = [file for file in lista if file.endswith('.csv') or file.endswith('.xlsx')]\n",
    "\n",
    "    print(f\"‚úÖ Archivos CSV/Excel v√°lidos: {len(files)}\")\n",
    "    for i, f in enumerate(files, 1):\n",
    "        print(f\"   {i}. {f}\")\n",
    "    print('*' * 80)\n",
    "    return files\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b121ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para leer archivos CSV o Excel.\n",
    "def leer_archivos(ruta_completa):\n",
    "    try:\n",
    "        ruta_completa = ruta_completa.strip()\n",
    "        _, extension = os.path.splitext(ruta_completa.lower())\n",
    "\n",
    "        if extension == '.csv':\n",
    "            # Creamos la variable encodings para normalizar el codigo.\n",
    "            encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']\n",
    "            \n",
    "            for encoding in encodings:\n",
    "                try:\n",
    "                    df = pd.read_csv(ruta_completa, sep=None, engine='python', encoding=encoding)\n",
    "                    print(f\"   ‚úì Codificaci√≥n exitosa: {encoding}\")\n",
    "                    return df\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "            \n",
    "            # Comprobamos si existe algun tipo de error de codificaci√≥n.\n",
    "            print(f\"   ‚ö†Ô∏è No se pudo decodificar con codificaciones est√°ndar\")\n",
    "            return None\n",
    "            \n",
    "        elif extension in ('.xlsx', '.xls'):\n",
    "            df = pd.read_excel(ruta_completa)\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è Formato no compatible: {extension}\")\n",
    "            return None\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ‚ùå Archivo no encontrado: '{ruta_completa}'\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error inesperado: {type(e).__name__}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0009e9",
   "metadata": {},
   "source": [
    "## Funciones exploracion inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09b6b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion exploracion inicial de datos.\n",
    "def exploracion_datos(df):\n",
    "    print('Exploraci√≥n inicial de datos:')\n",
    "    print('*'*100)\n",
    "\n",
    "    # Informaci√≥n general del dataframe.\n",
    "    num_filas, num_columnas = df.shape\n",
    "    print(f'El numero de filas es: {num_filas}\\nEl numero de columnas es: {num_columnas}')\n",
    "    print('*'*100)\n",
    "\n",
    "    # Exploracion visulal de las primeras, √∫ltimas y aleatorias filas del dataframe.\n",
    "    print('Las 5 primeras filas del dataframe son:')\n",
    "    display(df.head())\n",
    "    print('*'*100)\n",
    "    print('Las 5 √∫ltimas filas del dataframe son:')\n",
    "    display(df.tail())\n",
    "    print('*'*100)\n",
    "    print('Muestra aleatoria de 5 filas del dataframe:')\n",
    "    display(df.sample(5))\n",
    "    print('*'*100)\n",
    "\n",
    "    # Estadisticos descriptivos del dataframe.\n",
    "    print('Estad√≠sticos descriptivos del dataframe:')\n",
    "    display(df.describe())\n",
    "    print('*'*100)\n",
    "\n",
    "    # Resumen de tipologia de datos, visualizacion de nulos y valores unicos.\n",
    "    print('Resumen de tipolog√≠a de datos, visualizaci√≥n de nulos y valores √∫nicos:')\n",
    "    df_tipos=df.dtypes.to_frame(name='Tipos de datos')\n",
    "    df_nulos=df.isnull().sum().to_frame(name='Nulos')\n",
    "    df_porc_nulos = (df.isnull().sum() / len(df) * 100).to_frame(name='Porcentaje Nulos')\n",
    "    df_valores_unicos = pd.DataFrame(df.apply(lambda x: x.unique()))\n",
    "    df_valores_nunicos = pd.DataFrame(df.apply(lambda x: x.nunique()))\n",
    "    df_por_valores_nunicos=pd.DataFrame(df.apply(lambda x: x.nunique())/df.shape[0]*100)\n",
    "    df_valores_unicos.rename(columns={0:'Valores unicos'}, inplace=True)\n",
    "    df_valores_nunicos.rename(columns={0:'Numero valores unicos'}, inplace=True)\n",
    "    df_por_valores_nunicos.rename(columns={0:'Porcentaje valores unicos'}, inplace=True)\n",
    "    df_exploracion = pd.concat([df_tipos, df_nulos, df_porc_nulos,df_valores_nunicos,df_por_valores_nunicos,df_valores_unicos], axis=1)\n",
    "    \n",
    "    # MOSTRAR el resumen final\n",
    "    display(df_exploracion)\n",
    "    print('*'*100)\n",
    "    \n",
    "    return df_exploracion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab029e6",
   "metadata": {},
   "source": [
    "## Funciones limpieza y preparacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a981db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para renombrar columnas originales.\n",
    "def renombrar_columnas(df):\n",
    "    nombre_columnas = ['age', 'job', 'marital_status', 'education', 'credit_default', 'housing_loan', 'personal_loan',\n",
    "       'contact_type', 'last_contact_month', 'last_contact_day', 'last_contact_duration_secs', \n",
    "       'number_contacts', 'number_days_last_contact','number_of_previous_contacts', \n",
    "       'outcome_previous_campaign', 'employement_variation_rate', 'consumer_price_index','consumer_confidence_index', \n",
    "       'euribor_3m', 'number_employees', 'subscribed_term_deposit', 'age_group',\n",
    "       'last_contact_duration_mins', 'last_contact_duration_mins_group',\n",
    "       'employement_variation_rate_group','consumer_price_index_group','consumer_confidence_index_group','euribor_3m_group']\n",
    "    df.columns = nombre_columnas\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5276e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para normalizar textos.\n",
    "def normalizar_textos(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns: # Iteramos sobre columnas de tipo object.\n",
    "        df[col]=df[col].str.lower() # Convertimos a min√∫sculas.\n",
    "        df[col]=df[col].str.strip() # Eliminamos espacios en blanco al inicio y final.\n",
    "        df[col]=df[col].str.replace(r'\\.+$', '', regex=True) # Eliminamos los '.' al final de las cadenas de texto.\n",
    "        df[col]=df[col].str.replace(r'(?<=\\w)\\.+(?=\\w)', '_', regex=True) # Reemplazamos los '.' entre palabras por '_'.\n",
    "        df[col]=df[col].str.replace(r'(?<=\\w)-+(?=\\w)', '_', regex=True) # Reemplazamos los '-' entre palabras por '_'.\n",
    "        dict_job={'admin':'administrative_staff'}\n",
    "        if col=='job':\n",
    "            df[col]=df[col].replace(dict_job)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a23116ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion convertir columnas a tipo categ√≥rico.\n",
    "def columnas_categoricas(df):\n",
    "    # Listas categorias.\n",
    "    lista_categorias_job=['unknown','unemployed','student','retired','housemaid', 'services','blue_collar',\n",
    "                        'self_employed',  'administrative_staff',  'technician','entrepreneur','management']\n",
    "    lista_marital_status=['unknown','single','married','divorced']\n",
    "    lista_categorias_education=['unknown','illiterate','basic_4y','basic_6y', 'basic_9y', \n",
    "                                    'high_school', 'professional_course',  'university_degree']\n",
    "    lista_credit_default=['unknown','yes','no']\n",
    "    lista_housing_loan=['unknown','yes','no']\n",
    "    lista_personal_loan=['unknown','yes','no']\n",
    "    lista_contact_type=['telephone','cellular']\n",
    "    lista_last_contact_month=['mar', 'apr','may', 'jun', 'jul', 'aug','sep', 'oct', 'nov', 'dec']\n",
    "    lista_last_contact_day=['mon', 'tue', 'wed', 'thu', 'fri']\n",
    "    lista_outcome_previous_campaign=['nonexistent', 'failure', 'success']\n",
    "    lista_age_group=['18 - 25', '26 - 35', '36 - 45', '46 - 55', '56 - 65', '65+']\n",
    "    lista_last_contact_duration_mins=['0 - 1','1 - 2','2 - 3','3 - 5','5 - 10','10 - 20','20+']\n",
    "    lista_employement_variation_rate_group=['< -0.5','-0.5 - 0','0 - 0.5','> 0.5']\n",
    "    lista_consumer_price_index_group=['<90','90 - 94','94 - 100','100 - 104','104+']\n",
    "    lista_consumer_confidence_index_group=['<=-35', '-35 - 0', '0 - 35','35 - 100','> 100']\n",
    "    lista_euribor_3m_group=['<0','0 - 1','1 - 2','2 - 3','3 - 4','4 - 5','5+']\n",
    "\n",
    "    # Convertir columnas a tipo categ√≥rico segun las listas definidas.\n",
    "    df['job'] = pd.Categorical(df['job'], categories=lista_categorias_job, ordered=False)\n",
    "    df['marital_status'] = pd.Categorical(df['marital_status'], categories=lista_marital_status, ordered=False)\n",
    "    df['education'] = pd.Categorical(df['education'], categories=lista_categorias_education, ordered=False)\n",
    "    df['credit_default'] = pd.Categorical(df['credit_default'], categories=lista_credit_default, ordered=False)\n",
    "    df['housing_loan'] = pd.Categorical(df['housing_loan'], categories=lista_housing_loan, ordered=False)\n",
    "    df['personal_loan'] = pd.Categorical(df['personal_loan'], categories=lista_personal_loan, ordered=False)\n",
    "    df['contact_type'] = pd.Categorical(df['contact_type'], categories=lista_contact_type, ordered=False)\n",
    "    df['last_contact_month'] = pd.Categorical(df['last_contact_month'], categories=lista_last_contact_month, ordered=True)\n",
    "    df['last_contact_day'] = pd.Categorical(df['last_contact_day'], categories=lista_last_contact_day, ordered=False)\n",
    "    df['outcome_previous_campaign'] = pd.Categorical(df['outcome_previous_campaign'], categories=lista_outcome_previous_campaign, ordered=False)\n",
    "    df['age_group']=pd.Categorical(df['age_group'],categories=lista_age_group,ordered=False)\n",
    "    df['last_contact_duration_mins_group']=pd.Categorical(df['last_contact_duration_mins_group'],categories=lista_last_contact_duration_mins,ordered=False)\n",
    "    df['employement_variation_rate_group']=pd.Categorical(df['employement_variation_rate_group'],categories=lista_employement_variation_rate_group,ordered=False)\n",
    "    df['consumer_price_index_group']=pd.Categorical(df['consumer_price_index_group'],categories=lista_consumer_price_index_group,ordered=False)\n",
    "    df['consumer_confidence_index_group']=pd.Categorical(df['consumer_confidence_index_group'],categories=lista_consumer_confidence_index_group,ordered=False)\n",
    "    df['euribor_3m_group']=pd.Categorical(df['euribor_3m_group'],categories=lista_euribor_3m_group,ordered=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6390a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion cambiar columna subscribed_term_deposit a binario.\n",
    "def normalizar_binario(df):\n",
    "    dict_subscribed_term_deposit={'yes':1,'no':0} #Creamos un dicionario.\n",
    "    nulos=set(df.subscribed_term_deposit)-set(dict_subscribed_term_deposit.keys()) # Comprobamos si hay valores no contemplados en el diccionario.\n",
    "    if nulos:\n",
    "        print(f'Existen valores nulos en la columna subscribed_term_deposit: {nulos}') # Si hay valores no contemplados, los mostramos.\n",
    "    df.subscribed_term_deposit=df.subscribed_term_deposit.replace(dict_subscribed_term_deposit)\n",
    "    df.subscribed_term_deposit = df.subscribed_term_deposit.astype('int64') # Convertimos a int64."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8a72b",
   "metadata": {},
   "source": [
    "## Funciones graficos y obtencion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ccf9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para graficar heatmap y obtener chi2, p y dof y tabla de contingencia.\n",
    "def heatmap_correlation(df,df_2,columna,title,ylable):\n",
    "\n",
    "    # Calculamos chi2, p, dof\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(df)\n",
    "\n",
    "    # Creamos la figura.\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Creamos heatmap entre age_group y la suscripcion de un deposito.\n",
    "    sns.heatmap(\n",
    "        df,\n",
    "        annot=True,        \n",
    "        fmt='.2%',            \n",
    "        cmap='YlGnBu',        \n",
    "        cbar_kws={'label': 'Porcentaje'},\n",
    "        linewidths=0.5,\n",
    "        linecolor='gray')\n",
    "\n",
    "    plt.title(title, \n",
    "            fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.ylabel(ylable, fontsize=12)\n",
    "\n",
    "    # Creamos un conteo y porcentaje de los indices del dataframe a graficar sobre el dataframe original\n",
    "    df_values=df_2[columna].value_counts().to_frame().transpose()\n",
    "    df_values_norm=(df_2[columna].value_counts(normalize=True)*100).to_frame().transpose()\n",
    "    print(f\"chi2={chi2:.4f}, p={p:.4f}, dof={dof}\")\n",
    "    print(\"*\" * 80)\n",
    "    display(df_values)\n",
    "    print(\"*\" * 80)\n",
    "    display(df_values_norm)\n",
    "    print(\"*\" * 80)\n",
    "    display(df)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ed7f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para crear un histograma de barras para la correlacion de Spearman.\n",
    "def grafico_correlacion_spearman(df,df_2,title):\n",
    "\n",
    "    # Creamos la figura\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    # Extraemos los datos del dataframe\n",
    "    x_positions = df.index \n",
    "    y_values = df['subscribed_term_deposit'] \n",
    "\n",
    "    # Creamos el grafico de barras\n",
    "    bars = ax.bar(\n",
    "        x=x_positions,      \n",
    "        height=y_values,   \n",
    "        color=\"coral\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.8)\n",
    "\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(\"Correlaci√≥n\", fontsize=12, fontweight='bold')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    plt.setp(ax.get_xticklabels(), ha='right')\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # Creamos un conteo de los indices del dataframe a graficar sobre el dataframe original\n",
    "    for col in df.index:\n",
    "        df_values=df_2[col].value_counts().to_frame().transpose()\n",
    "        df_values_norm=(df_2[col].value_counts(normalize=True)*100).to_frame().transpose()\n",
    "        display(df_values)\n",
    "        display(df_values_norm)\n",
    "        print(\"*\" * 80)\n",
    "    display(df)\n",
    "    print(\"*\" * 80)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
